{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Seminar 4. Classification & Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Some remarks on home works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:50%; text-align:center\">\n",
    "<img src=https://4.bp.blogspot.com/-0cbXveb1J_0/V-FtjJZ4rqI/AAAAAAAAMHM/bS32Pio2a1IFOyp5T86S0jiyB-3KAN1iwCEw/s1600/download%2B%25281%2529.png width=500px>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### [Cancer](http://archive.ics.uci.edu/ml/datasets/Cervical+cancer+%28Risk+Factors%29)\n",
    "Predict cervical cancer using a set of demographic characteristics and medical tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### [Drugs](http://archive.ics.uci.edu/ml/datasets/Drug+consumption+%28quantified%29)\n",
    "Predict drug consumption using a set of demographic characteristics and five personality measurements (Links to an external site.)Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### [Facebook](http://archive.ics.uci.edu/ml/datasets/Facebook+metrics#)\n",
    "Predict popularity of Facebook posts using a set of very high-level features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### [Student](http://archive.ics.uci.edu/ml/datasets/Student+Performance)\n",
    "Predict students grades (math and Portugal) using a set of demographic features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Examples of supervised DS problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Iris Data Set\n",
    "https://archive.ics.uci.edu/ml/datasets/Iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant\n",
    "\n",
    "This is perhaps the best known database to be found in the pattern recognition literature. \n",
    "\n",
    "Fisher's paper is a classic in the field and is referenced frequently to this day. (See Duda & Hart, for example.) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Inputs // Features // X**: Flower sizes  \n",
    "  1. sepal length in cm \n",
    "  2. sepal width in cm \n",
    "  3. petal length in cm \n",
    "  4. petal width in cm \n",
    "  \n",
    "<div style=\"width:25%; text-align:center\">\n",
    "<img src=http://sebastianraschka.com/images/blog/2014/linear-discriminant-analysis/iris_petal_sepal.png width=500px>\n",
    "</div>\n",
    "\n",
    "The picture is taken from a very detailed [blogpost](http://sebastianraschka.com/Articles/2014_python_lda.html) on Linear Discriminant analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Output // Target // Y**: Type of iris plant\n",
    " - Iris Setosa \n",
    " - Iris Versicolour \n",
    " - Iris Virginica\n",
    " \n",
    "<div style=\"width:100%; text-align:center\">\n",
    "<img src=http://articles.concreteinteractive.com/wp-content/uploads/2015/03/irises.png width=500px>\n",
    "</div>\n",
    "\n",
    "The picture is taken from a very detailed [blogpost](http://sebastianraschka.com/Articles/2014_python_lda.html) on Linear Discriminant analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Shuttle Landing Control Data Set\n",
    "https://archive.ics.uci.edu/ml/datasets/Shuttle+Landing+Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Determining the conditions under which an autolanding would be preferable to manual control of the spacecraft.\n",
    "\n",
    "<div style=\"width:30%; text-align:center\">\n",
    "<img src=https://archive.ics.uci.edu/ml/assets/MLimages/Large92.jpg width=500px>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Inputs // Features // X**: Flight conditions  \n",
    "\n",
    "2. STABILITY: stab, xstab \n",
    "3. ERROR: XL, LX, MM, SS \n",
    "4. SIGN: pp, nn \n",
    "5. WIND: head, tail \n",
    "6. MAGNITUDE: Low, Medium, Strong, OutOfRange \n",
    "7. VISIBILITY: yes, no\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "** Output // Target // Y**: Type of control\n",
    "\n",
    "Auto or manual landing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mice Protein Expression Data Set\n",
    "https://archive.ics.uci.edu/ml/datasets/Mice+Protein+Expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The data set consists of the expression levels of 77 proteins that produced detectable signals in the nuclear fraction of cortex.\n",
    "- There are 38 control mice and 34 trisomic mice (Down syndrome). \n",
    "- In the experiments, 15 measurements were registered of each protein per sample/mouse. \n",
    "- Therefore, for control mice, there are 38x15, or 570 measurements, and for trisomic mice, there are 34x15, or 510 measurements. So, the dataset contains a total of 1080 measurements per protein. \n",
    "- Each measurement can be considered as an independent sample/mouse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Classes: \n",
    " - c-CS-s: control mice, stimulated to learn, injected with saline (9 mice) \n",
    " - c-CS-m: control mice, stimulated to learn, injected with memantine (10 mice) \n",
    " - c-SC-s: control mice, not stimulated to learn, injected with saline (9 mice) \n",
    " - c-SC-m: control mice, not stimulated to learn, injected with memantine (10 mice) \n",
    "\n",
    " - t-CS-s: trisomy mice, stimulated to learn, injected with saline (7 mice) \n",
    " - t-CS-m: trisomy mice, stimulated to learn, injected with memantine (9 mice) \n",
    " - t-SC-s: trisomy mice, not stimulated to learn, injected with saline (9 mice) \n",
    " - t-SC-m: trisomy mice, not stimulated to learn, injected with memantine (9 mice) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Inputs // Features // X**: the expression levels of 77 proteins \n",
    "\n",
    "** Output // Target // Y**: Control or trisomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Brief intro to classification algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import seminar4_utils as utils # plot functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "utils.plot_clf(LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sparcity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"width:60%; text-align:center\">\n",
    "<img src=https://1.bp.blogspot.com/-tXq6Nl2lcNg/V3qzttiZ4sI/AAAAAAAAN_M/6nmjgwydWJUy5Kqt9gFg2Nb12BCTcD4ogCLcB/s1600/LASSO.png>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_clf(LogisticRegression(C=1e-1, penalty='l1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC # SVC means Support Vector Classifier\n",
    "utils.plot_clf(SVC(kernel='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Kernel trick**. Main idea\n",
    "* SVM builds a linear decision boundary in a feature space\n",
    "* Some problems cannot be solved by a linear method (Problem 1 above)\n",
    "* But what if we somehow transform our feature space?\n",
    "* For example, use $x_1^2,\\; x_1 x_2, \\; x_2^2$ as features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# reload(utils)\n",
    "utils.plot_clf(SVC(kernel='poly', degree=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### We can even use infinite-dimensional vector spaces!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "utils.plot_clf(SVC(kernel='rbf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exploring the *Titanic* dataset (continued)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"width:100%; text-align:center\">\n",
    "<img src=http://upload.wikimedia.org/wikipedia/commons/6/6e/St%C3%B6wer_Titanic.jpg width=500px>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Kaggle has a nice [dataset](https://www.kaggle.com/c/titanic-gettingStarted) with information about passengers on the *Titanic*. It's meant as an introduction to predictive models -- here, predicting who survived the sinking. Let's explore it using [seaborn](http://stanford.edu/~mwaskom/software/seaborn/). This notebook mostly demonstrates features in development for version 0.3. Please [get in touch](https://github.com/mwaskom/seaborn/issues/new) if you have ideas for how they could be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "% pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.github.com/mattdelhey/kaggle-titanic/master/Data/train.csv\"\n",
    "titanic = pd.read_csv(url)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "titanic = titanic.drop([\"name\", \"ticket\", \"cabin\"], axis=1)\n",
    "titanic[\"sex\"] = titanic.sex.map({\"male\":0, \"female\":1})\n",
    "titanic = pd.get_dummies(titanic, dummy_na=True, columns=['embarked',])\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "X = titanic.drop('survived', axis=1)\n",
    "y = titanic.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# we have to remove NaN\n",
    "X.dropna(axis=0, inplace=True)\n",
    "print(X.count())\n",
    "y = y[X.index].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "clf.fit(X, y)\n",
    "y_predicted = clf.predict(X)\n",
    "print('Accuracy of prediction is {}'.format(accuracy_score(y, y_predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Bias-variance tradeoff\n",
    "\n",
    "<div style=\"width:100%; text-align:center\">\n",
    "<img src=http://scott.fortmann-roe.com/docs/docs/BiasVariance/biasvariance.png width=500px>\n",
    "</div>\n",
    "\n",
    "Check a great tutorial http://scott.fortmann-roe.com/docs/BiasVariance.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "clf.fit(X_train, y_train)\n",
    "y_predicted = clf.predict(X_train)\n",
    "print('Accuracy of prediction on train set is {}'.format(accuracy_score(y_train, y_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "y_predicted = clf.predict(X_test)\n",
    "print('Accuracy of prediction on test set is {}'.format(accuracy_score(y_test, y_predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Lets try to reproduce model complexity curves\n",
    "What is a measure of complexity for KNeighborsClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "train_error, test_error = [], []\n",
    "neighbors_range = range(1, 50)\n",
    "for n_neighbors in neighbors_range:\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_error.append(accuracy_score(y_train, clf.predict(X_train)))\n",
    "    test_error.append(accuracy_score(y_test, clf.predict(X_test)))\n",
    "plt.plot(neighbors_range, train_error)\n",
    "plt.plot(neighbors_range, test_error)\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.ylabel('Accuracy of prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Example: Mice classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Mice Protein Expression Data Set\n",
    "https://archive.ics.uci.edu/ml/datasets/Mice+Protein+Expression\n",
    "- The data set consists of the expression levels of 77 proteins that produced detectable signals in the nuclear fraction of cortex.\n",
    "- There are 38 control mice and 34 trisomic mice (Down syndrome). \n",
    "- In the experiments, 15 measurements were registered of each protein per sample/mouse. \n",
    "- Therefore, for control mice, there are 38x15, or 570 measurements, and for trisomic mice, there are 34x15, or 510 measurements. So, the dataset contains a total of 1080 measurements per protein. \n",
    "- Each measurement can be considered as an independent sample/mouse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "TODO: 1. Import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "TODO: 2. Load the Mice data set (check out *pd.read_* functions) and have a look at it\n",
    "\n",
    "*tip*: add index_col='MouseID' to yuor reading function to use Mouse Id as an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# We have 3 points with large number of NAs. Here we drop them\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "TODO: 3. Identify features (X) and targets (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " - c-CS-s: control mice, stimulated to learn, injected with saline (9 mice) \n",
    " - c-CS-m: control mice, stimulated to learn, injected with memantine (10 mice) \n",
    " - c-SC-s: control mice, not stimulated to learn, injected with saline (9 mice) \n",
    " - c-SC-m: control mice, not stimulated to learn, injected with memantine (10 mice) \n",
    "\n",
    " - t-CS-s: trisomy mice, stimulated to learn, injected with saline (7 mice) \n",
    " - t-CS-m: trisomy mice, stimulated to learn, injected with memantine (9 mice) \n",
    " - t-SC-s: trisomy mice, not stimulated to learn, injected with saline (9 mice) \n",
    " - t-SC-m: trisomy mice, not stimulated to learn, injected with memantine (9 mice) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "TODO: 4. Split your data into X and y\n",
    "\n",
    "*tip* you can assign data to X and drop unnecessary columns via drop() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "TODO: 5. Decode Genotype: Control as 0, Ts65Dn as 1\n",
    "    \n",
    "*tip* example from the titanic dataset: sex decoding\n",
    "\n",
    "titanic.sex = titanic.sex.map({\"male\":0, \"female\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "TODO: 6. Check NA values via count() and then drop columns with NaNs via dropna()\n",
    "\n",
    "*tip* check that you specify the correct axes to drop columns (and not rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "# LogisticRegressionCV automatically select regularization parameter C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegressionCV()\n",
    "clf.fit(X, y)\n",
    "print('Accuracy when trained on all dataset', np.mean(clf.predict(X) == y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, stratify = None, random_state = 0)\n",
    "\n",
    "# TODO: 7. Fit on train set & estimate accuracy on the test set\n",
    "clf = LogisticRegressionCV()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('Accuracy when trained on a training subset', np.mean(y_pred == y_test))\n",
    "# error is a little bit higher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Kfolds CV\n",
    "\n",
    "Example of 5-fold\n",
    "\n",
    "<div style=\"width:60%; text-align:center\">\n",
    "<img src=http://vinhkhuc.github.io/assets/2015-03-01-cross-validation/5-fold-cv.png>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "# KFold split your data\n",
    "# cross_val_score automatically builds K models and then estimates errors on the corresponding test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5) # 5-fold CV\n",
    "cv = kfold.split(X, y) # show data & make the split\n",
    "\n",
    "clf = LogisticRegressionCV()\n",
    "scores = cross_val_score(clf, X, y, scoring='accuracy', cv=cv)\n",
    "print('KFold score: {0:.3f} ± {1:.3f}'.format(scores.mean(), scores.std()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Wow! Significant drop in accuracy and rise in std across folds.  The reason is that the labels are ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 7. Check the order of the labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: 8. Try KFold with shuffle=True \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So, we restore our good accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Label(Group) split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### We have 15 measurments per mouse in the dataset, and our validation scheme doesn't take this fact into account. Let's fix that using group split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 measurments for the same mouse seem to be correlated\n",
    "X.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# generat list of mice_ids\n",
    "mice_id = X.index.map(lambda x: x.split('_')[0])\n",
    "mice_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "# GroupKFold allows to put all points with coincident labels into the single set (training one or validation one) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "group_kfold = GroupKFold(n_splits=5)\n",
    "cv = group_kfold.split(X, y, groups=mice_id) #we explicitly define our groups using mice_id\n",
    "\n",
    "scores = cross_val_score(clf, X, y, scoring='accuracy', cv=cv)\n",
    "print('LabelKFold score: {0:.3f} ± {1:.3f}'.format(scores.mean(), scores.std()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Classification accuracy is dropped. The reason is that there is no leak in our data anymore - we can't use data from \"validation\" mice during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Cross-validation: summary\n",
    "- Do not estimate accuracy on the train set, use a separate validation set\n",
    "- If your labels are ordered, don't forget to shuffle your data\n",
    "- If you have any groups in your dataset, you have to use GroupKFold to estimate quality of your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Metrics for classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Precision & Recall\n",
    "A wonderfull picture from Wikipedia\n",
    "<div style=\"width:75%; text-align:center\">\n",
    "<img src=https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/525px-Precisionrecall.svg.png width=500px>\n",
    "</div>\n",
    "\n",
    "\n",
    "F1 = 2 \\* (precision \\* recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_predict\n",
    "# cross_val_predict internally do KFold cross-validation, calculate predictions on validation sets\n",
    "# and then merge predictions into a single vector of predictions\n",
    "from sklearn.metrics import classification_report\n",
    "#classification_report gives several quality metrics. It can be used for multiclass problems\n",
    "\n",
    "y_pred = cross_val_predict(LogisticRegressionCV(), X, y)\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "####  By default cross_val_predict use KFold without shuffle, so the quality is dropped again. We can explicitly specify the correct CV scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "kfold = GroupKFold(n_splits=5)\n",
    "y_pred = cross_val_predict(LogisticRegressionCV(), X, y, cv=kfold.split(X, y, mice_id))\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let us explore precision & recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"width:100%; text-align:center\">\n",
    "<img src=./binary_classification.png>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##  SECOM Data Set\n",
    "https://archive.ics.uci.edu/ml/datasets/SECOM\n",
    "\n",
    "Data from a semi-conductor manufacturing process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# download inputs\n",
    "import pandas as pd\n",
    "path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom.data'\n",
    "X = pd.read_csv(path, sep=' ', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# We have several points with large number of NAs. Here we drop them\n",
    "print(X.shape)\n",
    "X.dropna(thresh=550, axis=0, inplace=True)\n",
    "print(X.shape)\n",
    "# drop columns with any NaN\n",
    "X.dropna(axis=1, inplace=True)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom_labels.data'\n",
    "y = pd.read_csv(path, sep=' ', header=None)[0]\n",
    "y = y[X.index]\n",
    "y = y == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### TODO 1:\n",
    " - Import from sklearn.metrics accuracy, precision and recall scores; \n",
    " - also import train_test_split from cross_validation \n",
    " - split data into train & test parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### TODO 2: estimate Precision, Recall on train set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### TODO 3: estimate Accuracy, Precision, Recall on test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Awful results on the test set. Any ideas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probably, we can select better value of regularization parameter C\n",
    "#### TODO 4: replace LogisticRegression by LogisticRegressionCV & check the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### No progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### But, components of our data have significantly different ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.max(0) - X.min(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), LogisticRegressionCV(scoring='recall'))\n",
    "\n",
    "# TODO 5: estimate quality metrics on both train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links\n",
    " - [A blog post on cross validation](http://sebastianraschka.com/blog/2016/model-evaluation-selection-part3.html)\n",
    " - Also, check out two other posts from the same series \"Model evaluation, model selection, and algorithm selection in machine learning\": [The basics](http://sebastianraschka.com/blog/2016/model-evaluation-selection-part1.html) and [Bootstrapping and uncertainties](http://sebastianraschka.com/blog/2016/model-evaluation-selection-part2.html)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
